{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionTextualTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ISVRL4K3vbc",
        "outputId": "c008e3ce-1dd2-4f2e-df52-81d440b3a495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Bidirectional,LSTM,GRU,Dense\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ4Khl9T4SYH"
      },
      "source": [
        "num_classes=5\n",
        "embed_num_dims=300\n",
        "max_seq_len=500\n",
        "class_names=['joy','fear','anger','sadness','neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ0M4Y9o4c8l"
      },
      "source": [
        "data_train=pd.read_csv('drive/My Drive/data_train.csv',encoding='utf-8')\n",
        "data_test=pd.read_csv('drive/My Drive/data_test.csv',encoding='utf-8')\n",
        "X_train=data_train['Text']\n",
        "X_test=data_test['Text']\n",
        "y_train=data_train['Emotion']\n",
        "y_test=data_test['Emotion']\n",
        "data=data_train.append(data_test,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJLHiBzP4yhY"
      },
      "source": [
        "def clean_text(data):\n",
        "    data=re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
        "    data=re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
        "    data=word_tokenize(data)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd2eOPZ47116",
        "outputId": "42989286-d1ff-4a76-e8ff-67feef031c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "texts=[' '.join(clean_text(text)) for text in data.Text]\n",
        "texts_train=[' '.join(clean_text(text)) for text in X_train]\n",
        "texts_test=[' '.join(clean_text(text)) for text in X_test]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a bit ? I 'm extremely annoyed that he did n't phone me when he promised me that he would ! He 's such a liar .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSh71gA7_VC",
        "outputId": "d991557e-1592-46f7-9cc5-f184c6e71bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequence_train=tokenizer.texts_to_sequences(texts_train)\n",
        "sequence_test=tokenizer.texts_to_sequences(texts_test)\n",
        "index_of_words=tokenizer.word_index\n",
        "vocab_size=len(index_of_words)+1\n",
        "print('Number of unique words: {}'.format(len(index_of_words)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 12088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rV8gvGx8XWQ",
        "outputId": "afb5110b-13dd-40e8-ee62-54011af3c7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_pad=pad_sequences(sequence_train,maxlen=max_seq_len)\n",
        "X_test_pad=pad_sequences(sequence_test,maxlen=max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   119,    51,   345],\n",
              "       [    0,     0,     0, ...,    37,   277,   154],\n",
              "       [    0,     0,     0, ...,    16,     2,  1210],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   876,     4,   909],\n",
              "       [    0,     0,     0, ...,     1,     6,   117],\n",
              "       [    0,     0,     0, ..., 10259,   173,    13]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vx4LGOe8nTR"
      },
      "source": [
        "encoding={'joy':0,'fear':1,'anger':2,'sadness':3,'neutral':4}\n",
        "y_train=[encoding[x] for x in data_train.Emotion]\n",
        "y_test=[encoding[x] for x in data_test.Emotion]\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTM-gofJ9Eh-"
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size=len(word_index)+1\n",
        "    embedding_matrix=np.zeros((vocab_size,embedding_dim))\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word,*vector=line.split()\n",
        "            if word in word_index:\n",
        "                idx=word_index[word]\n",
        "                embedding_matrix[idx] = np.array(vector,dtype=np.float32)[:embedding_dim]\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Jz-fvs9sZy",
        "outputId": "e5c1ee93-2fda-48f0-f1cc-fe608989d54a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fname='embeddings/wiki-news-300d-1M.vec'\n",
        "if not os.path.isfile(fname):\n",
        "    print('Downloading word vectors...')\n",
        "    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip','wiki-news-300d-1M.vec.zip')\n",
        "    print('Unzipping...')\n",
        "    with zipfile.ZipFile('wiki-news-300d-1M.vec.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('embeddings')\n",
        "    print('done.')\n",
        "    os.remove('wiki-news-300d-1M.vec.zip')\n",
        "embedd_matrix=create_embedding_matrix(fname,index_of_words,embed_num_dims)\n",
        "embedd_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading word vectors...\n",
            "Unzipping...\n",
            "done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12089, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ova3m_-xlc"
      },
      "source": [
        "embedd_layer=Embedding(vocab_size,embed_num_dims,input_length=max_seq_len,weights=[embedd_matrix],trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzHNN515_Mo_",
        "outputId": "364e8371-7944-437c-cc55-233bfa2fbaac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gru_output_size=128\n",
        "bidirectional=True\n",
        "model=Sequential()\n",
        "model.add(embedd_layer)\n",
        "if bidirectional:\n",
        "    model.add(Bidirectional(GRU(units=gru_output_size,dropout=0.2,recurrent_dropout=0.2)))\n",
        "else:\n",
        "    model.add(GRU(units=gru_output_size,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDA8oiuy_rYC",
        "outputId": "5f34360e-5e29-4893-93b2-95ed0010f97c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 300)          3626700   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               330240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 3,958,225\n",
            "Trainable params: 331,525\n",
            "Non-trainable params: 3,626,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIRlOeDz_3E5",
        "outputId": "2b718c2a-8dc9-4402-bbc9-82de67c32c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size=128\n",
        "epochs=15\n",
        "model.fit(X_train_pad,y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_test_pad,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "62/62 [==============================] - 198s 3s/step - loss: 1.4152 - accuracy: 0.3857 - val_loss: 1.2716 - val_accuracy: 0.4492\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 199s 3s/step - loss: 1.1127 - accuracy: 0.5615 - val_loss: 0.9920 - val_accuracy: 0.6286\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 200s 3s/step - loss: 0.8838 - accuracy: 0.6707 - val_loss: 0.8503 - val_accuracy: 0.6897\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 201s 3s/step - loss: 0.7926 - accuracy: 0.7126 - val_loss: 0.7921 - val_accuracy: 0.7094\n",
            "Epoch 5/15\n",
            "62/62 [==============================] - 204s 3s/step - loss: 0.7528 - accuracy: 0.7257 - val_loss: 0.8076 - val_accuracy: 0.7094\n",
            "Epoch 6/15\n",
            "62/62 [==============================] - 205s 3s/step - loss: 0.7221 - accuracy: 0.7377 - val_loss: 0.7669 - val_accuracy: 0.7262\n",
            "Epoch 7/15\n",
            "62/62 [==============================] - 206s 3s/step - loss: 0.6980 - accuracy: 0.7460 - val_loss: 0.7641 - val_accuracy: 0.7230\n",
            "Epoch 8/15\n",
            "62/62 [==============================] - 209s 3s/step - loss: 0.6894 - accuracy: 0.7511 - val_loss: 0.7601 - val_accuracy: 0.7221\n",
            "Epoch 9/15\n",
            "62/62 [==============================] - 205s 3s/step - loss: 0.6544 - accuracy: 0.7628 - val_loss: 0.7523 - val_accuracy: 0.7291\n",
            "Epoch 10/15\n",
            "62/62 [==============================] - 195s 3s/step - loss: 0.6382 - accuracy: 0.7751 - val_loss: 0.7326 - val_accuracy: 0.7350\n",
            "Epoch 11/15\n",
            "62/62 [==============================] - 199s 3s/step - loss: 0.6268 - accuracy: 0.7749 - val_loss: 0.7320 - val_accuracy: 0.7342\n",
            "Epoch 12/15\n",
            "62/62 [==============================] - 196s 3s/step - loss: 0.6014 - accuracy: 0.7856 - val_loss: 0.7394 - val_accuracy: 0.7321\n",
            "Epoch 13/15\n",
            "62/62 [==============================] - 197s 3s/step - loss: 0.5892 - accuracy: 0.7861 - val_loss: 0.7345 - val_accuracy: 0.7330\n",
            "Epoch 14/15\n",
            "62/62 [==============================] - 196s 3s/step - loss: 0.5871 - accuracy: 0.7912 - val_loss: 0.7401 - val_accuracy: 0.7350\n",
            "Epoch 15/15\n",
            "62/62 [==============================] - 197s 3s/step - loss: 0.5655 - accuracy: 0.7964 - val_loss: 0.7399 - val_accuracy: 0.7353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w29F3LigARQ5",
        "outputId": "f93cbd29-dd87-4f21-c63d-6ff5fe0f8274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "message=['I am so happy I am going to cry.']\n",
        "seq=tokenizer.texts_to_sequences(message)\n",
        "padded=pad_sequences(seq,maxlen=max_seq_len)\n",
        "pred=model.predict(padded)\n",
        "print('Message:'+str(message))\n",
        "print('Emotion:',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message:['I am so happy I am going to cry.']\n",
            "Emotion: [[9.576078e-01 3.789285e-03 3.220642e-03 3.461444e-02 7.678335e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jg4V_gKUj4d"
      },
      "source": [
        "tf.keras.models.save_model(model,'drive/My Drive/textmodel1',overwrite=True,include_optimizer=True,save_format=None,signatures=None,options=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCO17smaUzzf"
      },
      "source": [
        "textmodel2=tf.keras.models.load_model('drive/My Drive/textmodel2',custom_objects=None,compile=True,options=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}